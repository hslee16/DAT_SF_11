{
 "metadata": {
  "name": "",
  "signature": "sha256:08dce04c2c9bd486edc9c657d903508d77d809393447f97cb51ddd574f217ee3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "IPython Parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Adopted from Scikit-learn Tutorial at SciPy2013 by [Olivier Grisel](https://github.com/ogrisel/parallel_ml_tutorial)\n",
      "\n",
      "Outline of the session:\n",
      "\n",
      "- Introduction to **IPython.parallel**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Motivation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When doing model evaluations and parameters tuning, many models must be trained independently on the same data. This is an embarrassingly parallel problem but having a copy of the dataset in memory for each process is waste of RAM."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "IPython.parallel, a Primer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section gives a primer on some tools best utilizing computational resources when doing predictive modeling in the Python / NumPy ecosystem namely:\n",
      "\n",
      "- optimal usage of available CPUs and cluster nodes with **`IPython.parallel`**\n",
      "\n",
      "- optimal memory re-use using shared memory between Python processes using **`numpy.memmap`** and **`joblib`**\n",
      "\n",
      "### What is so great about `IPython.parallel`:\n",
      "\n",
      "- Single node multi-CPUs\n",
      "- Multiple node multi-CPUs\n",
      "- Interactive In-memory computing\n",
      "- IPython notebook integration with `%px` and `%%px` magics\n",
      "- Possibility to interactively connect to individual computing processes to launch interactive debugger (`#priceless`)\n",
      "\n",
      "### Let's get started:\n",
      "\n",
      "Go to the \"Cluster\" tab of the notebook and **start a local cluster with 2 engines**. Then come back here:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(client)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### The %px and %%px magics\n",
      "\n",
      "All the engines of the client can be accessed imperatively using the `%px` and `%%px` IPython cell magics:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "\n",
      "import os\n",
      "import socket\n",
      "\n",
      "print(\"This is running in process with pid {0} on host '{1}'.\".format(\n",
      "      os.getpid(), socket.gethostname()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] This is running in process with pid 5956 on host 'Rameshs-MacBook-Pro.local'.\n",
        "[stdout:1] This is running in process with pid 5958 on host 'Rameshs-MacBook-Pro.local'.\n",
        "[stdout:2] This is running in process with pid 5957 on host 'Rameshs-MacBook-Pro.local'.\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The content of the `__main__` namespace can also be read and written via the `%px` magic:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px a = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px print(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] 1\n",
        "[stdout:1] 1\n",
        "[stdout:2] 1\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "\n",
      "a *= 2\n",
      "print(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] 2\n",
        "[stdout:1] 2\n",
        "[stdout:2] 2\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible to restrict the `%px` and `%%px` magic instructions to specific engines:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --targets=-1\n",
      "a *= 2\n",
      "print(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px print(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] 2\n",
        "[stdout:1] 2\n",
        "[stdout:2] 4\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### The DirectView objects\n",
      "\n",
      "Cell magics are very nice to work interactively from the notebook but it's also possible to replicate their behavior programmatically with more flexibility with a `DirectView` instance. A `DirectView` can be created by slicing the client object:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_engines = client[:]\n",
      "all_engines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "<DirectView [0, 1, 2]>"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The namespace of the `__main__` module of each running python engine can be accessed in read and write mode as a python dictionary:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_engines['a'] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_engines['a']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[1, 1, 1]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Direct views can also execute the same code in parallel on each engine of the view:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_sum(a, b):\n",
      "    return a + b\n",
      "\n",
      "my_sum_apply_results = all_engines.apply(my_sum, 11, 31)\n",
      "my_sum_apply_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "<AsyncResult: my_sum>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The ouput of the `apply` method is an asynchronous handle returned immediately without waiting for the end of the computation. To block until the results are ready use:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my_sum_apply_results.get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[42, 42, 42]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is a more useful example to fetch the network hostname of each engine in the cluster. Let's study it in more details:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def hostname():\n",
      "    \"\"\"Return the name of the host where the function is being called\"\"\"\n",
      "    import socket\n",
      "    return socket.gethostname()\n",
      "\n",
      "hostname_apply_result = all_engines.apply(hostname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When doing the above, the `hostname` function is first defined locally (the client python process). The `DirectView.apply` method introspects it, serializes its name and bytecode and ships it to each engine of the cluster where it is reconstructed as local function on each engine. This function is then called on each engine of the view with the optionally provided arguments.\n",
      "\n",
      "In return, the client gets a python object that serves as an handle to asynchronously fetch the list of the results of the calls:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hostname_apply_result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "<AsyncResult: finished>"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hostname_apply_result.get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "['Rameshs-MacBook-Pro.local',\n",
        " 'Rameshs-MacBook-Pro.local',\n",
        " 'Rameshs-MacBook-Pro.local']"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also possible to key the results explicitly with the engine ids with the `AsyncResult.get_dict` method. This is a very simple idiom to fetch metadata on the runtime environment of each engine of the direct view:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hostnames = hostname_apply_result.get_dict()\n",
      "hostnames"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "{0: 'Rameshs-MacBook-Pro.local',\n",
        " 1: 'Rameshs-MacBook-Pro.local',\n",
        " 2: 'Rameshs-MacBook-Pro.local'}"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It can be handy to invert this mapping to find one engine id per host in the cluster so as to execute host specific operation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "one_engine_by_host = dict((hostname, engine_id) for engine_id, hostname\n",
      "                      in hostnames.items())\n",
      "one_engine_by_host"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "{'Rameshs-MacBook-Pro.local': 2}"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "one_engine_per_host_view = client[one_engine_by_host.values()]\n",
      "one_engine_per_host_view"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "<DirectView [2]>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Trick:** you can even use those engines ids to execute shell commands in parallel on each host of the cluster:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "one_engine_by_host.values()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "[2]"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "\n",
      "!pip install psutil"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] Requirement already satisfied (use --upgrade to upgrade): psutil in /Users/sampathweb/miniconda/envs/conda27/lib/python2.7/site-packages\r\n",
        "[stdout:1] Requirement already satisfied (use --upgrade to upgrade): psutil in /Users/sampathweb/miniconda/envs/conda27/lib/python2.7/site-packages\r\n",
        "[stdout:2] Requirement already satisfied (use --upgrade to upgrade): psutil in /Users/sampathweb/miniconda/envs/conda27/lib/python2.7/site-packages\r\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Note on Importing Modules on Remote Engines\n",
      "\n",
      "In the previous example we put the `import socket` statement inside the body of the `hostname` function to make sure to make sure that is is available when the rest of the function is executed in the python processes of the remote engines.\n",
      "\n",
      "Alternatively it is possible to import the required modules ahead of time on all the engines of a directview using a context manager / with syntax:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with all_engines.sync_imports():\n",
      "    import numpy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "importing numpy on engine(s)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However this method does **not** support alternative import syntaxes:\n",
      "    \n",
      "    >>> import numpy as np\n",
      "    >>> from numpy import linalg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hence the method of importing in the body of the \"applied\" functions is more flexible. Additionally, this does not pollute the `__main__` namespace of the engines as it only impact the local namespace of the function itself."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- Write a function that returns the memory usage of each engine process in the cluster.\n",
      "- Allocate a largish numpy array of zeros of known size (e.g. 100MB) on each engine of the cluster.\n",
      "\n",
      "Hints:\n",
      "\n",
      "Use the `psutil` module to collect the runtime info on a specific process or host. For instance to fetch the memory usage of the currently running process in MB:\n",
      "\n",
      "    >>> import os\n",
      "    >>> import psutil\n",
      "    >>> psutil.Process(os.getpid()).get_memory_info().rss / 1e6\n",
      "\n",
      "To allocate a numpy array with 1000 zeros stored as 64bit floats you can use:\n",
      "\n",
      "    >>> import numpy as np\n",
      "    >>> z = np.zeros(1000, dtype=np.float64)\n",
      "\n",
      "The size in bytes of such a numpy array can then be fetched with ``z.nbytes``:\n",
      "    \n",
      "    >>> z.nbytes / 1e6\n",
      "    0.008"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_engines_memory(client):\n",
      "    def memory_mb():\n",
      "        import os, psutil\n",
      "        return psutil.Process(os.getpid()).get_memory_info().rss / 1e6\n",
      "    \n",
      "    return client[:].apply(memory_mb).get_dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_engines_memory(client)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "{0: 31.76448, 1: 31.813632, 2: 31.8464}"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(get_engines_memory(client).values())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "95.453184"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Load Balanced View"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`LoadBalancedView` is an alternative to the `DirectView` to run one function call at a time on a free engine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lv = client.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def slow_square(x):\n",
      "    import time\n",
      "    time.sleep(2)\n",
      "    return x ** 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = lv.apply(slow_square, 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "<AsyncResult: slow_square>"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result.ready()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result.get()  # blocking call"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "16"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible to spread some tasks among the engines of the LB view by passing a callable and an iterable of task arguments to the `LoadBalancedView.map` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = lv.map(slow_square, [0, 1, 2, 3])\n",
      "results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "<AsyncMapResult: slow_square>"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results.ready()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results.progress"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# results.abort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Iteration on AsyncMapResult is blocking\n",
      "for r in results:\n",
      "    print(r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1\n",
        "4\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The load balanced view will be used in the following to schedule work on the cluster while being able to monitor progress and occasionally add new computing nodes to the cluster while computing to speed up the processing when using EC2 and StarCluster (see later)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}